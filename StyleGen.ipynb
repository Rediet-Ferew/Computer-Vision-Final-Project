{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGNTYI8K9ZMw",
        "outputId": "cdbe8444-bacf-4b7f-fb61-f126bcd3c0d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons) (24.1)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow_addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow_addons\n",
            "Successfully installed tensorflow_addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJ6MB4Nb9jtd",
        "outputId": "6ea6f9af-8084-4318-8f5f-18693feddeef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow_addons.layers import InstanceNormalization\n",
        "\n",
        "import gdown\n",
        "from zipfile import ZipFile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_t-fIcY9rMK"
      },
      "outputs": [],
      "source": [
        "def log2(x):\n",
        "    return int(np.log2(x))\n",
        "\n",
        "\n",
        "# we use different batch size for different resolution, so larger image size\n",
        "# could fit into GPU memory. The keys is image resolution in log2\n",
        "batch_sizes = {2: 16, 3: 16, 4: 16, 5: 16, 6: 16, 7: 8, 8: 4, 9: 2, 10: 1}\n",
        "# We adjust the train step accordingly\n",
        "train_step_ratio = {k: batch_sizes[2] / v for k, v in batch_sizes.items()}\n",
        "\n",
        "\n",
        "os.makedirs(\"celeba_gan\")\n",
        "\n",
        "url = \"https://drive.google.com/uc?id=1O7m1010EJjLE5QxLZiM9Fpjs7Oj6e684\"\n",
        "output = \"celeba_gan/data.zip\"\n",
        "gdown.download(url, output, quiet=True)\n",
        "\n",
        "with ZipFile(\"celeba_gan/data.zip\", \"r\") as zipobj:\n",
        "    zipobj.extractall(\"celeba_gan\")\n",
        "\n",
        "# Create a dataset from our folder, and rescale the images to the [0-1] range:\n",
        "\n",
        "ds_train = keras.utils.image_dataset_from_directory(\n",
        "    \"celeba_gan\", label_mode=None, image_size=(64, 64), batch_size=32\n",
        ")\n",
        "\n",
        "\n",
        "def resize_image(res, image):\n",
        "    # only downsampling, so use nearest neighbor that is faster to run\n",
        "    image = tf.image.resize(\n",
        "        image, (res, res), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR\n",
        "    )\n",
        "    image = tf.cast(image, tf.float32) / 127.5 - 1.0\n",
        "    return image\n",
        "\n",
        "\n",
        "def create_dataloader(res):\n",
        "    batch_size = batch_sizes[log2(res)]\n",
        "    # NOTE: we unbatch the dataset so we can `batch()` it again with the `drop_remainder=True` option\n",
        "    # since the model only supports a single batch size\n",
        "    dl = ds_train.map(partial(resize_image, res), num_parallel_calls=tf.data.AUTOTUNE).unbatch()\n",
        "    dl = dl.shuffle(200).batch(batch_size, drop_remainder=True).prefetch(1).repeat()\n",
        "    return dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "S_x2iKwg96x2"
      },
      "outputs": [],
      "source": [
        "def plot_images(images, log2_res, fname=\"\"):\n",
        "    scales = {2: 0.5, 3: 1, 4: 2, 5: 3, 6: 4, 7: 5, 8: 6, 9: 7, 10: 8}\n",
        "    scale = scales[log2_res]\n",
        "\n",
        "    grid_col = min(images.shape[0], int(32 // scale))\n",
        "    grid_row = 1\n",
        "\n",
        "    f, axarr = plt.subplots(\n",
        "        grid_row, grid_col, figsize=(grid_col * scale, grid_row * scale)\n",
        "    )\n",
        "\n",
        "    for row in range(grid_row):\n",
        "        ax = axarr if grid_row == 1 else axarr[row]\n",
        "        for col in range(grid_col):\n",
        "            ax[col].imshow(images[row * grid_col + col])\n",
        "            ax[col].axis(\"off\")\n",
        "    plt.show()\n",
        "    if fname:\n",
        "        f.savefig(fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mwdiKTaB-x63"
      },
      "outputs": [],
      "source": [
        "def fade_in(alpha, a, b):\n",
        "    return alpha * a + (1.0 - alpha) * b\n",
        "\n",
        "\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "    return -tf.reduce_mean(y_true * y_pred)\n",
        "\n",
        "\n",
        "def pixel_norm(x, epsilon=1e-8):\n",
        "    return x / tf.math.sqrt(tf.reduce_mean(x ** 2, axis=-1, keepdims=True) + epsilon)\n",
        "\n",
        "\n",
        "def minibatch_std(input_tensor, epsilon=1e-8):\n",
        "    n, h, w, c = tf.shape(input_tensor)\n",
        "    group_size = tf.minimum(4, n)\n",
        "    x = tf.reshape(input_tensor, [group_size, -1, h, w, c])\n",
        "    group_mean, group_var = tf.nn.moments(x, axes=(0), keepdims=False)\n",
        "    group_std = tf.sqrt(group_var + epsilon)\n",
        "    avg_std = tf.reduce_mean(group_std, axis=[1, 2, 3], keepdims=True)\n",
        "    x = tf.tile(avg_std, [group_size, h, w, 1])\n",
        "    return tf.concat([input_tensor, x], axis=-1)\n",
        "\n",
        "\n",
        "class EqualizedConv(layers.Layer):\n",
        "    def __init__(self, out_channels, kernel=3, gain=2, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.kernel = kernel\n",
        "        self.out_channels = out_channels\n",
        "        self.gain = gain\n",
        "        self.pad = kernel != 1\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.in_channels = input_shape[-1]\n",
        "        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n",
        "        self.w = self.add_weight(\n",
        "            shape=[self.kernel, self.kernel, self.in_channels, self.out_channels],\n",
        "            initializer=initializer,\n",
        "            trainable=True,\n",
        "            name=\"kernel\",\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.out_channels,), initializer=\"zeros\", trainable=True, name=\"bias\"\n",
        "        )\n",
        "        fan_in = self.kernel * self.kernel * self.in_channels\n",
        "        self.scale = tf.sqrt(self.gain / fan_in)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.pad:\n",
        "            x = tf.pad(inputs, [[0, 0], [1, 1], [1, 1], [0, 0]], mode=\"REFLECT\")\n",
        "        else:\n",
        "            x = inputs\n",
        "        output = (\n",
        "            tf.nn.conv2d(x, self.scale * self.w, strides=1, padding=\"VALID\") + self.b\n",
        "        )\n",
        "        return output\n",
        "\n",
        "\n",
        "class EqualizedDense(layers.Layer):\n",
        "    def __init__(self, units, gain=2, learning_rate_multiplier=1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.units = units\n",
        "        self.gain = gain\n",
        "        self.learning_rate_multiplier = learning_rate_multiplier\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.in_channels = input_shape[-1]\n",
        "        initializer = keras.initializers.RandomNormal(\n",
        "            mean=0.0, stddev=1.0 / self.learning_rate_multiplier\n",
        "        )\n",
        "        self.w = self.add_weight(\n",
        "            shape=[self.in_channels, self.units],\n",
        "            initializer=initializer,\n",
        "            trainable=True,\n",
        "            name=\"kernel\",\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,), initializer=\"zeros\", trainable=True, name=\"bias\"\n",
        "        )\n",
        "        fan_in = self.in_channels\n",
        "        self.scale = tf.sqrt(self.gain / fan_in)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = tf.add(tf.matmul(inputs, self.scale * self.w), self.b)\n",
        "        return output * self.learning_rate_multiplier\n",
        "\n",
        "\n",
        "class AddNoise(layers.Layer):\n",
        "    def build(self, input_shape):\n",
        "        n, h, w, c = input_shape[0]\n",
        "        initializer = keras.initializers.RandomNormal(mean=0.0, stddev=1.0)\n",
        "        self.b = self.add_weight(\n",
        "            shape=[1, 1, 1, c], initializer=initializer, trainable=True, name=\"kernel\"\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, noise = inputs\n",
        "        output = x + self.b * noise\n",
        "        return output\n",
        "\n",
        "\n",
        "class AdaIN(layers.Layer):\n",
        "    def __init__(self, gain=1, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.gain = gain\n",
        "\n",
        "    def build(self, input_shapes):\n",
        "        x_shape = input_shapes[0]\n",
        "        w_shape = input_shapes[1]\n",
        "\n",
        "        self.w_channels = w_shape[-1]\n",
        "        self.x_channels = x_shape[-1]\n",
        "\n",
        "        self.dense_1 = EqualizedDense(self.x_channels, gain=1)\n",
        "        self.dense_2 = EqualizedDense(self.x_channels, gain=1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, w = inputs\n",
        "        ys = tf.reshape(self.dense_1(w), (-1, 1, 1, self.x_channels))\n",
        "        yb = tf.reshape(self.dense_2(w), (-1, 1, 1, self.x_channels))\n",
        "        return ys * x + yb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wSTHUkbm-9xG"
      },
      "outputs": [],
      "source": [
        "def Mapping(num_stages, input_shape=512):\n",
        "    z = layers.Input(shape=(input_shape))\n",
        "    w = pixel_norm(z)\n",
        "    for i in range(8):\n",
        "        w = EqualizedDense(512, learning_rate_multiplier=0.01)(w)\n",
        "        w = layers.LeakyReLU(0.2)(w)\n",
        "    w = tf.tile(tf.expand_dims(w, 1), (1, num_stages, 1))\n",
        "    return keras.Model(z, w, name=\"mapping\")\n",
        "\n",
        "\n",
        "class Generator:\n",
        "    def __init__(self, start_res_log2, target_res_log2):\n",
        "        self.start_res_log2 = start_res_log2\n",
        "        self.target_res_log2 = target_res_log2\n",
        "        self.num_stages = target_res_log2 - start_res_log2 + 1\n",
        "        # list of generator blocks at increasing resolution\n",
        "        self.g_blocks = []\n",
        "        # list of layers to convert g_block activation to RGB\n",
        "        self.to_rgb = []\n",
        "        # list of noise input of different resolutions into g_blocks\n",
        "        self.noise_inputs = []\n",
        "        # filter size to use at each stage, keys are log2(resolution)\n",
        "        self.filter_nums = {\n",
        "            0: 512,\n",
        "            1: 512,\n",
        "            2: 512,  # 4x4\n",
        "            3: 512,  # 8x8\n",
        "            4: 512,  # 16x16\n",
        "            5: 512,  # 32x32\n",
        "            6: 256,  # 64x64\n",
        "            7: 128,  # 128x128\n",
        "            8: 64,  # 256x256\n",
        "            9: 32,  # 512x512\n",
        "            10: 16,\n",
        "        }  # 1024x1024\n",
        "\n",
        "        start_res = 2 ** start_res_log2\n",
        "        self.input_shape = (start_res, start_res, self.filter_nums[start_res_log2])\n",
        "        self.g_input = layers.Input(self.input_shape, name=\"generator_input\")\n",
        "\n",
        "        for i in range(start_res_log2, target_res_log2 + 1):\n",
        "            filter_num = self.filter_nums[i]\n",
        "            res = 2 ** i\n",
        "            self.noise_inputs.append(\n",
        "                layers.Input(shape=(res, res, 1), name=f\"noise_{res}x{res}\")\n",
        "            )\n",
        "            to_rgb = Sequential(\n",
        "                [\n",
        "                    layers.InputLayer(input_shape=(res, res, filter_num)),\n",
        "                    EqualizedConv(3, 1, gain=1),\n",
        "                ],\n",
        "                name=f\"to_rgb_{res}x{res}\",\n",
        "            )\n",
        "            self.to_rgb.append(to_rgb)\n",
        "            is_base = i == self.start_res_log2\n",
        "            if is_base:\n",
        "                input_shape = (res, res, self.filter_nums[i - 1])\n",
        "            else:\n",
        "                input_shape = (2 ** (i - 1), 2 ** (i - 1), self.filter_nums[i - 1])\n",
        "            g_block = self.build_block(\n",
        "                filter_num, res=res, input_shape=input_shape, is_base=is_base\n",
        "            )\n",
        "            self.g_blocks.append(g_block)\n",
        "\n",
        "    def build_block(self, filter_num, res, input_shape, is_base):\n",
        "        input_tensor = layers.Input(shape=input_shape, name=f\"g_{res}\")\n",
        "        noise = layers.Input(shape=(res, res, 1), name=f\"noise_{res}\")\n",
        "        w = layers.Input(shape=512)\n",
        "        x = input_tensor\n",
        "\n",
        "        if not is_base:\n",
        "            x = layers.UpSampling2D((2, 2))(x)\n",
        "            x = EqualizedConv(filter_num, 3)(x)\n",
        "\n",
        "        x = AddNoise()([x, noise])\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = InstanceNormalization()(x)\n",
        "        x = AdaIN()([x, w])\n",
        "\n",
        "        x = EqualizedConv(filter_num, 3)(x)\n",
        "        x = AddNoise()([x, noise])\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = InstanceNormalization()(x)\n",
        "        x = AdaIN()([x, w])\n",
        "        return keras.Model([input_tensor, w, noise], x, name=f\"genblock_{res}x{res}\")\n",
        "\n",
        "    def grow(self, res_log2):\n",
        "        res = 2 ** res_log2\n",
        "\n",
        "        num_stages = res_log2 - self.start_res_log2 + 1\n",
        "        w = layers.Input(shape=(self.num_stages, 512), name=\"w\")\n",
        "\n",
        "        alpha = layers.Input(shape=(1), name=\"g_alpha\")\n",
        "        x = self.g_blocks[0]([self.g_input, w[:, 0], self.noise_inputs[0]])\n",
        "\n",
        "        if num_stages == 1:\n",
        "            rgb = self.to_rgb[0](x)\n",
        "        else:\n",
        "            for i in range(1, num_stages - 1):\n",
        "\n",
        "                x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n",
        "\n",
        "            old_rgb = self.to_rgb[num_stages - 2](x)\n",
        "            old_rgb = layers.UpSampling2D((2, 2))(old_rgb)\n",
        "\n",
        "            i = num_stages - 1\n",
        "            x = self.g_blocks[i]([x, w[:, i], self.noise_inputs[i]])\n",
        "\n",
        "            new_rgb = self.to_rgb[i](x)\n",
        "\n",
        "            rgb = fade_in(alpha[0], new_rgb, old_rgb)\n",
        "\n",
        "        return keras.Model(\n",
        "            [self.g_input, w, self.noise_inputs, alpha],\n",
        "            rgb,\n",
        "            name=f\"generator_{res}_x_{res}\",\n",
        "        )\n",
        "\n",
        "\n",
        "class Discriminator:\n",
        "    def __init__(self, start_res_log2, target_res_log2):\n",
        "        self.start_res_log2 = start_res_log2\n",
        "        self.target_res_log2 = target_res_log2\n",
        "        self.num_stages = target_res_log2 - start_res_log2 + 1\n",
        "        # filter size to use at each stage, keys are log2(resolution)\n",
        "        self.filter_nums = {\n",
        "            0: 512,\n",
        "            1: 512,\n",
        "            2: 512,  # 4x4\n",
        "            3: 512,  # 8x8\n",
        "            4: 512,  # 16x16\n",
        "            5: 512,  # 32x32\n",
        "            6: 256,  # 64x64\n",
        "            7: 128,  # 128x128\n",
        "            8: 64,  # 256x256\n",
        "            9: 32,  # 512x512\n",
        "            10: 16,\n",
        "        }  # 1024x1024\n",
        "        # list of discriminator blocks at increasing resolution\n",
        "        self.d_blocks = []\n",
        "        # list of layers to convert RGB into activation for d_blocks inputs\n",
        "        self.from_rgb = []\n",
        "\n",
        "        for res_log2 in range(self.start_res_log2, self.target_res_log2 + 1):\n",
        "            res = 2 ** res_log2\n",
        "            filter_num = self.filter_nums[res_log2]\n",
        "            from_rgb = Sequential(\n",
        "                [\n",
        "                    layers.InputLayer(\n",
        "                        input_shape=(res, res, 3), name=f\"from_rgb_input_{res}\"\n",
        "                    ),\n",
        "                    EqualizedConv(filter_num, 1),\n",
        "                    layers.LeakyReLU(0.2),\n",
        "                ],\n",
        "                name=f\"from_rgb_{res}\",\n",
        "            )\n",
        "\n",
        "            self.from_rgb.append(from_rgb)\n",
        "\n",
        "            input_shape = (res, res, filter_num)\n",
        "            if len(self.d_blocks) == 0:\n",
        "                d_block = self.build_base(filter_num, res)\n",
        "            else:\n",
        "                d_block = self.build_block(\n",
        "                    filter_num, self.filter_nums[res_log2 - 1], res\n",
        "                )\n",
        "\n",
        "            self.d_blocks.append(d_block)\n",
        "\n",
        "    def build_base(self, filter_num, res):\n",
        "        input_tensor = layers.Input(shape=(res, res, filter_num), name=f\"d_{res}\")\n",
        "        x = minibatch_std(input_tensor)\n",
        "        x = EqualizedConv(filter_num, 3)(x)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = layers.Flatten()(x)\n",
        "        x = EqualizedDense(filter_num)(x)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = EqualizedDense(1)(x)\n",
        "        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n",
        "\n",
        "    def build_block(self, filter_num_1, filter_num_2, res):\n",
        "        input_tensor = layers.Input(shape=(res, res, filter_num_1), name=f\"d_{res}\")\n",
        "        x = EqualizedConv(filter_num_1, 3)(input_tensor)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = EqualizedConv(filter_num_2)(x)\n",
        "        x = layers.LeakyReLU(0.2)(x)\n",
        "        x = layers.AveragePooling2D((2, 2))(x)\n",
        "        return keras.Model(input_tensor, x, name=f\"d_{res}\")\n",
        "\n",
        "    def grow(self, res_log2):\n",
        "        res = 2 ** res_log2\n",
        "        idx = res_log2 - self.start_res_log2\n",
        "        alpha = layers.Input(shape=(1), name=\"d_alpha\")\n",
        "        input_image = layers.Input(shape=(res, res, 3), name=\"input_image\")\n",
        "        x = self.from_rgb[idx](input_image)\n",
        "        x = self.d_blocks[idx](x)\n",
        "        if idx > 0:\n",
        "            idx -= 1\n",
        "            downsized_image = layers.AveragePooling2D((2, 2))(input_image)\n",
        "            y = self.from_rgb[idx](downsized_image)\n",
        "            x = fade_in(alpha[0], x, y)\n",
        "\n",
        "            for i in range(idx, -1, -1):\n",
        "                x = self.d_blocks[i](x)\n",
        "        return keras.Model([input_image, alpha], x, name=f\"discriminator_{res}_x_{res}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "J6_VSytC_KUM"
      },
      "outputs": [],
      "source": [
        "class StyleGAN(tf.keras.Model):\n",
        "    def __init__(self, z_dim=512, target_res=64, start_res=4):\n",
        "        super().__init__()\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.target_res_log2 = log2(target_res)\n",
        "        self.start_res_log2 = log2(start_res)\n",
        "        self.current_res_log2 = self.target_res_log2\n",
        "        self.num_stages = self.target_res_log2 - self.start_res_log2 + 1\n",
        "\n",
        "        self.alpha = tf.Variable(1.0, dtype=tf.float32, trainable=False, name=\"alpha\")\n",
        "\n",
        "        self.mapping = Mapping(num_stages=self.num_stages)\n",
        "        self.d_builder = Discriminator(self.start_res_log2, self.target_res_log2)\n",
        "        self.g_builder = Generator(self.start_res_log2, self.target_res_log2)\n",
        "        self.g_input_shape = self.g_builder.input_shape\n",
        "\n",
        "        self.phase = None\n",
        "        self.train_step_counter = tf.Variable(0, dtype=tf.int32, trainable=False)\n",
        "\n",
        "        self.loss_weights = {\"gradient_penalty\": 10, \"drift\": 0.001}\n",
        "\n",
        "    def grow_model(self, res):\n",
        "        tf.keras.backend.clear_session()\n",
        "        res_log2 = log2(res)\n",
        "        self.generator = self.g_builder.grow(res_log2)\n",
        "        self.discriminator = self.d_builder.grow(res_log2)\n",
        "        self.current_res_log2 = res_log2\n",
        "        print(f\"\\nModel resolution:{res}x{res}\")\n",
        "\n",
        "    def compile(\n",
        "        self, steps_per_epoch, phase, res, d_optimizer, g_optimizer, *args, **kwargs\n",
        "    ):\n",
        "        self.loss_weights = kwargs.pop(\"loss_weights\", self.loss_weights)\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        if res != 2 ** self.current_res_log2:\n",
        "            self.grow_model(res)\n",
        "            self.d_optimizer = d_optimizer\n",
        "            self.g_optimizer = g_optimizer\n",
        "\n",
        "        self.train_step_counter.assign(0)\n",
        "        self.phase = phase\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "        super().compile(*args, **kwargs)\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def generate_noise(self, batch_size):\n",
        "        noise = [\n",
        "            tf.random.normal((batch_size, 2 ** res, 2 ** res, 1))\n",
        "            for res in range(self.start_res_log2, self.target_res_log2 + 1)\n",
        "        ]\n",
        "        return noise\n",
        "\n",
        "    def gradient_loss(self, grad):\n",
        "        loss = tf.square(grad)\n",
        "        loss = tf.reduce_sum(loss, axis=tf.range(1, tf.size(tf.shape(loss))))\n",
        "        loss = tf.sqrt(loss)\n",
        "        loss = tf.reduce_mean(tf.square(loss - 1))\n",
        "        return loss\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "\n",
        "        self.train_step_counter.assign_add(1)\n",
        "\n",
        "        if self.phase == \"TRANSITION\":\n",
        "            self.alpha.assign(\n",
        "                tf.cast(self.train_step_counter / self.steps_per_epoch, tf.float32)\n",
        "            )\n",
        "        elif self.phase == \"STABLE\":\n",
        "            self.alpha.assign(1.0)\n",
        "        else:\n",
        "            raise NotImplementedError\n",
        "        alpha = tf.expand_dims(self.alpha, 0)\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        real_labels = tf.ones(batch_size)\n",
        "        fake_labels = -tf.ones(batch_size)\n",
        "\n",
        "        z = tf.random.normal((batch_size, self.z_dim))\n",
        "        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n",
        "        noise = self.generate_noise(batch_size)\n",
        "\n",
        "        # generator\n",
        "        with tf.GradientTape() as g_tape:\n",
        "            w = self.mapping(z)\n",
        "            fake_images = self.generator([const_input, w, noise, alpha])\n",
        "            pred_fake = self.discriminator([fake_images, alpha])\n",
        "            g_loss = wasserstein_loss(real_labels, pred_fake)\n",
        "\n",
        "            trainable_weights = (\n",
        "                self.mapping.trainable_weights + self.generator.trainable_weights\n",
        "            )\n",
        "            gradients = g_tape.gradient(g_loss, trainable_weights)\n",
        "            self.g_optimizer.apply_gradients(zip(gradients, trainable_weights))\n",
        "\n",
        "        # discriminator\n",
        "        with tf.GradientTape() as gradient_tape, tf.GradientTape() as total_tape:\n",
        "            # forward pass\n",
        "            pred_fake = self.discriminator([fake_images, alpha])\n",
        "            pred_real = self.discriminator([real_images, alpha])\n",
        "\n",
        "            epsilon = tf.random.uniform((batch_size, 1, 1, 1))\n",
        "            interpolates = epsilon * real_images + (1 - epsilon) * fake_images\n",
        "            gradient_tape.watch(interpolates)\n",
        "            pred_fake_grad = self.discriminator([interpolates, alpha])\n",
        "\n",
        "            # calculate losses\n",
        "            loss_fake = wasserstein_loss(fake_labels, pred_fake)\n",
        "            loss_real = wasserstein_loss(real_labels, pred_real)\n",
        "            loss_fake_grad = wasserstein_loss(fake_labels, pred_fake_grad)\n",
        "\n",
        "            # gradient penalty\n",
        "            gradients_fake = gradient_tape.gradient(loss_fake_grad, [interpolates])\n",
        "            gradient_penalty = self.loss_weights[\n",
        "                \"gradient_penalty\"\n",
        "            ] * self.gradient_loss(gradients_fake)\n",
        "\n",
        "            # drift loss\n",
        "            all_pred = tf.concat([pred_fake, pred_real], axis=0)\n",
        "            drift_loss = self.loss_weights[\"drift\"] * tf.reduce_mean(all_pred ** 2)\n",
        "\n",
        "            d_loss = loss_fake + loss_real + gradient_penalty + drift_loss\n",
        "\n",
        "            gradients = total_tape.gradient(\n",
        "                d_loss, self.discriminator.trainable_weights\n",
        "            )\n",
        "            self.d_optimizer.apply_gradients(\n",
        "                zip(gradients, self.discriminator.trainable_weights)\n",
        "            )\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }\n",
        "\n",
        "    def call(self, inputs: dict()):\n",
        "        style_code = inputs.get(\"style_code\", None)\n",
        "        z = inputs.get(\"z\", None)\n",
        "        noise = inputs.get(\"noise\", None)\n",
        "        batch_size = inputs.get(\"batch_size\", 1)\n",
        "        alpha = inputs.get(\"alpha\", 1.0)\n",
        "        alpha = tf.expand_dims(alpha, 0)\n",
        "        if style_code is None:\n",
        "            if z is None:\n",
        "                z = tf.random.normal((batch_size, self.z_dim))\n",
        "            style_code = self.mapping(z)\n",
        "\n",
        "        if noise is None:\n",
        "            noise = self.generate_noise(batch_size)\n",
        "\n",
        "        # self.alpha.assign(alpha)\n",
        "\n",
        "        const_input = tf.ones(tuple([batch_size] + list(self.g_input_shape)))\n",
        "        images = self.generator([const_input, style_code, noise, alpha])\n",
        "        images = np.clip((images * 0.5 + 0.5) * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "        return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FvLB79HO_RZC"
      },
      "outputs": [],
      "source": [
        "START_RES = 4\n",
        "TARGET_RES = 128\n",
        "\n",
        "style_gan = StyleGAN(start_res=START_RES, target_res=TARGET_RES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xmCpXrCV_Ubb"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    start_res=START_RES,\n",
        "    target_res=TARGET_RES,\n",
        "    steps_per_epoch=5000,\n",
        "    display_images=True,\n",
        "):\n",
        "    opt_cfg = {\"learning_rate\": 1e-3, \"beta_1\": 0.0, \"beta_2\": 0.99, \"epsilon\": 1e-8}\n",
        "\n",
        "    val_batch_size = 16\n",
        "    val_z = tf.random.normal((val_batch_size, style_gan.z_dim))\n",
        "    val_noise = style_gan.generate_noise(val_batch_size)\n",
        "\n",
        "    start_res_log2 = int(np.log2(start_res))\n",
        "    target_res_log2 = int(np.log2(target_res))\n",
        "\n",
        "    for res_log2 in range(start_res_log2, target_res_log2 + 1):\n",
        "        res = 2 ** res_log2\n",
        "        for phase in [\"TRANSITION\", \"STABLE\"]:\n",
        "            if res == start_res and phase == \"TRANSITION\":\n",
        "                continue\n",
        "\n",
        "            train_dl = create_dataloader(res)\n",
        "\n",
        "            steps = int(train_step_ratio[res_log2] * steps_per_epoch)\n",
        "\n",
        "            style_gan.compile(\n",
        "                d_optimizer=tf.keras.optimizers.legacy.Adam(**opt_cfg),\n",
        "                g_optimizer=tf.keras.optimizers.legacy.Adam(**opt_cfg),\n",
        "                loss_weights={\"gradient_penalty\": 10, \"drift\": 0.001},\n",
        "                steps_per_epoch=steps,\n",
        "                res=res,\n",
        "                phase=phase,\n",
        "                run_eagerly=False,\n",
        "            )\n",
        "\n",
        "            prefix = f\"res_{res}x{res}_{style_gan.phase}\"\n",
        "\n",
        "            ckpt_cb = keras.callbacks.ModelCheckpoint(\n",
        "                f\"checkpoints/stylegan_{res}x{res}.ckpt\",\n",
        "                save_weights_only=True,\n",
        "                verbose=0,\n",
        "            )\n",
        "            print(phase)\n",
        "            style_gan.fit(\n",
        "                train_dl, epochs=1, steps_per_epoch=steps, callbacks=[ckpt_cb]\n",
        "            )\n",
        "\n",
        "            if display_images:\n",
        "                images = style_gan({\"z\": val_z, \"noise\": val_noise, \"alpha\": 1.0})\n",
        "                plot_images(images, res_log2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkFTD94V_b8z",
        "outputId": "a3c34897-bd2c-41f8-f78a-743dafd20108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model resolution:4x4\n",
            "STABLE\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_train_function.<locals>.train_function at 0x78b28129b370> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/100 [==============================] - 124s 1s/step - d_loss: -2.1458 - g_loss: 1.5928\n",
            "\n",
            "Model resolution:8x8\n",
            "TRANSITION\n",
            "100/100 [==============================] - 496s 5s/step - d_loss: -15.6747 - g_loss: 29.8098\n",
            "STABLE\n",
            "100/100 [==============================] - 461s 5s/step - d_loss: -15.8304 - g_loss: 13.4674\n",
            "\n",
            "Model resolution:16x16\n",
            "TRANSITION\n",
            "100/100 [==============================] - 2002s 20s/step - d_loss: -33.0655 - g_loss: 32.3990\n",
            "STABLE\n",
            "100/100 [==============================] - 1947s 19s/step - d_loss: -32.1315 - g_loss: 25.4695\n"
          ]
        }
      ],
      "source": [
        "train(start_res=4, target_res=16, steps_per_epoch=100, display_images=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "jowLMkpl_gDL",
        "outputId": "d5b95b04-9f90-4e40-d08a-82c9d5892831"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "style_gan.load_weights(os.path.join(\"/content/checkpoints/stylegan_16x16.ckpt\"))\n",
        "\n",
        "tf.random.set_seed(196)\n",
        "batch_size = 2\n",
        "z = tf.random.normal((batch_size, style_gan.z_dim))\n",
        "w = style_gan.mapping(z)\n",
        "noise = style_gan.generate_noise(batch_size=batch_size)\n",
        "images = style_gan({\"style_code\": w, \"noise\": noise, \"alpha\": 1.0})\n",
        "plot_images(images, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za7xLG4oAOey"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
